{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234d50ee-8c03-4bbe-8157-ad6929a53954",
   "metadata": {},
   "source": [
    "## Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaabfc1-65af-4fe3-b636-3c8febda4d79",
   "metadata": {},
   "source": [
    "Underfitting means that your model makes accurate, but initially incorrect predictions. In this case, train error is large and val/test error is large too. Overfitting means that your model makes not accurate predictions. In this case, train error is very small and val/test error is large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a39c8a-4679-4f58-93ee-c11f8522cb30",
   "metadata": {},
   "source": [
    "## Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bfd06-2bfd-48b2-a2a4-c83e6dda0236",
   "metadata": {},
   "source": [
    "Here we will discuss possible options to prevent overfitting, which helps improve the model performance.\n",
    "1. Train with more data. ...\n",
    "2. Data augmentation. ...\n",
    "3. Addition of noise to the input data. ...\n",
    "4. Feature selection. ...\n",
    "5. Cross-validation. ...\n",
    "6. Simplify data. ...\n",
    "7. Regularization. ...\n",
    "8. Ensembling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d3b22-813e-47f7-87e6-83233dab9c6d",
   "metadata": {},
   "source": [
    "## Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71af0a-a664-4541-a6db-eca0c54ab516",
   "metadata": {},
   "source": [
    "What are different scenarios in which machine learning models underfitting can happen?\n",
    "Underfitting occurs when a model is too simple — informed by too few features or regularized too much — which makes it inflexible in learning from the dataset. Simple learners tend to have less variance in their predictions but more bias towards wrong outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9163b4-fa44-4e9b-9147-cc3063aee9b6",
   "metadata": {},
   "source": [
    "## Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c771d7-211b-4d80-aedb-efd8a042e71c",
   "metadata": {},
   "source": [
    "What is the bias-variance tradeoff in machine learning explain bias and variance?\n",
    "In statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dfa19f-642a-4fef-baf5-c3926a5072e2",
   "metadata": {},
   "source": [
    "## Q5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1779cf6-d80a-44b5-b67d-5444d756c7e4",
   "metadata": {},
   "source": [
    "How to identify overfitting and underfitting in machine learning?\n",
    "Image result for Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4106b-0571-422d-b71f-7d6ffa0599ac",
   "metadata": {},
   "source": [
    "## Q6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d78a6-0c17-4431-89f8-e16159b553a6",
   "metadata": {},
   "source": [
    "A model with high variance may represent the data set accurately but could lead to overfitting to noisy or otherwise unrepresentative training data. In comparison, a model with high bias may underfit the training data due to a simpler model that overlooks regularities in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9af96-8349-49ed-aeef-1e3602451cb1",
   "metadata": {},
   "source": [
    "## Q7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f0092-708a-4809-b8d6-8a44532ebdae",
   "metadata": {},
   "source": [
    "In short, Regularization in machine learning is the process of regularizing the parameters that constrain, regularizes, or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, avoiding the risk of Overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12c9fb-81d7-4065-8892-0b239cea76a5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
