{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8aeff6a-cf8c-46e7-9405-2416c9885b12",
   "metadata": {},
   "source": [
    "## Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce365c-e914-4966-997c-0f45ed1a28f3",
   "metadata": {},
   "source": [
    "Ridge regression is a term used to refer to a linear regression model whose coefficients are estimated not by ordinary least squares (OLS), but by an estimator, called ridge estimator, that, albeit biased, has lower variance than the OLS estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4942f40-5a20-498e-bfe0-9335b7d6fbba",
   "metadata": {},
   "source": [
    "## Q2. What are the assumptions of Ridge Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05fcc0d-36d6-4f15-81f9-844376df63f3",
   "metadata": {},
   "source": [
    "The assumptions of ridge regression are the same as that of linear regression: linearity, constant variance, and independence. However, as ridge regression does not provide confidence limits, the distribution of errors to be normal need not be assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081087f4-ce11-43ef-a4dc-a4bf980b54f5",
   "metadata": {},
   "source": [
    "## Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259a7a3-0675-4e7d-8076-95f7208eeb71",
   "metadata": {},
   "source": [
    "Selecting a good value for λ is critical. When λ=0, the penalty term has no effect, and ridge regression will produce the classical least square coefficients. However, as λ increases to infinite, the impact of the shrinkage penalty grows, and the ridge regression coefficients will get close zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7323b0-d176-4422-b586-9d84fcb760f6",
   "metadata": {},
   "source": [
    "## Q4. Can Ridge Regression be used for feature selection? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b295f-6bfb-4b69-a27b-6a86e4d7e333",
   "metadata": {},
   "source": [
    "We can use ridge regression for feature selection while fitting the model. In this article, we are going to use logistic regression for model fitting and push the parameter penalty as L2 which basically means the penalty we use in ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236bcf0-6939-4b3d-bbe3-2f27be288739",
   "metadata": {},
   "source": [
    "## Q5. How does the Ridge Regression model perform in the presence of multicollinearity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457feca8-778b-4afc-83fb-131928e7f2b3",
   "metadata": {},
   "source": [
    "When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value. By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37389628-7a6d-456a-aba4-f6d346cce5ae",
   "metadata": {},
   "source": [
    "## Q6. Can Ridge Regression handle both categorical and continuous independent variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0eec9d-97e7-41ae-8795-47a615585345",
   "metadata": {},
   "source": [
    "t seems that you are looking for a multinominal ridge regression: The short answer is Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0359f38-6dd0-4b81-91aa-c5a9361d4456",
   "metadata": {},
   "source": [
    "## Q7. How do you interpret the coefficients of Ridge Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf489d-fff5-4e69-81ce-81c3cd8e5336",
   "metadata": {},
   "source": [
    "What is the meaning of ridge regression coefficients?\n",
    "Image result for How do you interpret the coefficients of Ridge Regression?\n",
    "The ridge coefficients are a reduced factor of the simple linear regression coefficients and thus never attain zero values but very small values. The lasso coefficients become zero in a certain range and are reduced by a constant factor, which explains their low magnitude in comparison to the ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68daf0aa-b891-491e-9393-18cb3a13ee3f",
   "metadata": {},
   "source": [
    "## Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167f1b5-30ca-453b-b4ff-11339f838e2b",
   "metadata": {},
   "source": [
    "The ridge regression technique can be used to predict time-series. Ridge regression (RR) can also solve the multicollinearity problem that exists in linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47e956-bb2f-4180-b92b-4c59ae86a8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
